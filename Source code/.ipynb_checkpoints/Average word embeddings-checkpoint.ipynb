{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Average word embeddings\n",
    "\n",
    "Applying the strength of word embeddings or vectors to larger text formats, such as documents or sentences, is a very basic technique in NLP.\n",
    "\n",
    "Suppose we have a sentence **T** , which is composed of words $w_{1}$, $w_{2}$, ⋯, $w_{n}$. Each word has a embedding $uw_{1}$, $uw_{2}$, ⋯, $uw_{n}$. So we define the sentence embedding as: $u_{\\mathbf{T}}$:= $\\frac{1}{n}$ $\\sum_{i=1}^{n}$ ${w_{u_{i}}}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "from gensim.models import KeyedVectors\n",
    "from gensim.scripts.glove2word2vec import glove2word2vec\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from nltk.translate.bleu_score import sentence_bleu\n",
    "from nltk.translate.bleu_score import SmoothingFunction\n",
    "smoother = SmoothingFunction()\n",
    "from rouge.rouge import rouge_n_sentence_level # pip install easy-rouge\n",
    "from scipy.stats import pearsonr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\d072726\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\d072726\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# imports for preprocessing\n",
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize \n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pretrained word embeddings\n",
    "\n",
    "- Download fasttext embeddings [here](https://dl.fbaipublicfiles.com/fasttext/vectors-wiki/wiki.en.vec)\n",
    "- Download glove embeddings [here](http://nlp.stanford.edu/data/glove.840B.300d.zip)\n",
    "\n",
    "Unzip the glove embeddings and save the embeddings in a folder pretrained_embeddings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for convience convert the fasttext and glove embeddings to word2vec format\n",
    "\n",
    "# for using fasttext embeddings\n",
    "fasttext_model = KeyedVectors.load_word2vec_format('pretrained_embeddings/wiki.en.vec')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:gensim.scripts.glove2word2vec:converting 2196017 vectors from pretrained_embeddings/glove.840B.300d.txt to pretrained_embeddings/glove_word2vec.txt\n",
      "INFO:gensim.models.utils_any2vec:loading projection weights from pretrained_embeddings/glove_word2vec.txt\n",
      "WARNING:gensim.models.utils_any2vec:duplicate word '����������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������' in pretrained_embeddings/glove_word2vec.txt, ignoring all but first\n",
      "INFO:gensim.models.utils_any2vec:duplicate words detected, shrinking matrix size from 2196017 to 2196016\n",
      "INFO:gensim.models.utils_any2vec:loaded (2196016, 300) matrix from pretrained_embeddings/glove_word2vec.txt\n"
     ]
    }
   ],
   "source": [
    "# for using glove embeddings\n",
    "glove_file = 'pretrained_embeddings/glove.840B.300d.txt'\n",
    "tmp_file = 'pretrained_embeddings/glove_word2vec.txt'\n",
    "_ = glove2word2vec(glove_file, tmp_file)\n",
    "\n",
    "glove_model = KeyedVectors.load_word2vec_format(tmp_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load testsets for evaluation\n",
    "\n",
    "The Automatically generated texts (predictions) from machine translation or text summarization are evaluated against their reference texts. <br> Below are the testsets to be used for evaluation. \n",
    "\n",
    "- For **DE-EN** translation, <br>  **reference-** 'testsets/de-en/test2016.en.atok'   **prediction-** 'testsets/de-en/multi30k.test.pred.en.atok' <br>\n",
    "\n",
    "\n",
    "- For **RO-EN** translation, <br>  **reference-** 'testsets/ro-en/newstest2016_ref_1000.en'  **prediction-**- 'testsets/ro-en/newstest2016_output_1000.en'<br>\n",
    "\n",
    "\n",
    "- For **giga word** summarization(titles), <br>  **reference-** 'testsets/giga/task1_ref0_giga_450.txt'  **prediction-**'testsets/giga/giga.10_300000_450.txt'\n",
    "\n",
    "\n",
    "- For **CNN-DM** summariation, <br>  **reference-** 'testsets/cnn/preprocessed.ref'  **prediction-** 'testsets/cnn/preprocessed.pred'\n",
    "\n",
    "\n",
    "- For **Duc 2003** summarization, <br>  **reference-** 'testsets/duc/task1_ref0_duc2003.txt'  **prediction-** 'testsets/duc/duc2003.10_300000.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "metadata": {},
   "outputs": [],
   "source": [
    "reference_doc = 'testsets/de-en/test2016.en.atok'\n",
    "prediction_doc =  'testsets/de-en/multi30k.test.pred.en.atok'  \n",
    "\n",
    "with open( reference_doc ,'r') as ref, open( prediction_doc ,'r') as pred:\n",
    "    reference_en = ref.readlines()\n",
    "    prediction_en = pred.readlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['UN Chief Says There Is No Military Solution in Syria\\n',\n",
       " 'Secretary-General Ban Ki-moon says his response to Russia\\'s stepped up military support for Syria is that \"there is no military solution\" to the nearly five-year conflict and more weapons will only worsen the violence and misery for millions of people .\\n',\n",
       " 'The U .N . chief again urged all parties, including the divided U .N . Security Council, to unite and support inclusive negotiations to find a political solution .\\n',\n",
       " \"Ban told a news conference Wednesday that he plans to meet with foreign ministers of the five permanent council nations - the U .S ., Russia, China, Britain and France - on the sidelines of the General Assembly's ministerial session later this month to discuss Syria .\\n\",\n",
       " 'He expressed regret that divisions in the council and among the Syrian people and regional powers \"made this situation unsolvable .\"\\n']"
      ]
     },
     "execution_count": 225,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reference_en[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['UN chief says no military solutions to Syria\\n',\n",
       " \"Secretary General Ban Ki moon says Russia's response to Russia's military support for Syria is that there is no military solution to the conflict lasting nearly five years and more weapons would only exacerbate violence and suffering millions of people .\\n\",\n",
       " 'The UN chief urged all parties again , including the divided UN Security Council to unify and support negotiations in order to find a political solution .\\n',\n",
       " \"Ban said at a conference Wednesday that he planned to meet with foreign ministers from five permanent countries permanently present on the council this month - the US , Russia , China , England and France - on the edge of the General Assembly's ministerial session to discuss Syria .\\n\",\n",
       " 'Ban voiced regret that divisions within the council and between Syrian people and regional powers have made this intractable situation .\\n']"
      ]
     },
     "execution_count": 226,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction_en[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Optional preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessing(doc, stop_words_remove=False):\n",
    "    remove_punctuation = []\n",
    "    preprocessed_doc = []\n",
    "    # keep only alphanumeric characters(remove punctuations)\n",
    "    remove_punctuation = [re.sub(r\"[^\\w]\", \" \", sent).lower().strip() for sent in doc] \n",
    "    \n",
    "    if stop_words_remove == True:\n",
    "        # remove stop words requires lower cased tokens\n",
    "        stop_words = set(stopwords.words(\"english\"))\n",
    "        for sent in remove_punctuation:\n",
    "            filtered_sentence = [word for word in word_tokenize(sent.lower()) if not word in stop_words]\n",
    "            preprocessed_doc.append(' '.join(filtered_sentence))\n",
    "        return preprocessed_doc\n",
    "    else:\n",
    "        return remove_punctuation  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use only if you want to preprocess the sentences\n",
    "\n",
    "reference_en = preprocessing(reference_en, True) # True to remove stopwords, default only removes punctuation\n",
    "prediction_en = preprocessing(prediction_en, True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Semantic similarity scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "metadata": {},
   "outputs": [],
   "source": [
    "def document_vector(model, doc):\n",
    "    \n",
    "    # remove out-of-vocabulary words  \n",
    "    doc_tokenize = [word for word in doc.lower().split() if word in model.vocab]\n",
    "     \n",
    "    return np.mean(model[doc_tokenize], axis=0) #mean of the word embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "metadata": {},
   "outputs": [],
   "source": [
    "ref_embedding = []\n",
    "pred_embedding = []\n",
    "for doc in reference_en:\n",
    "    ref_embedding.append(document_vector(glove_model, doc)) #glove_model for using glove embeddings\n",
    "for doc in prediction_en:\n",
    "    pred_embedding.append(document_vector(glove_model, doc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "metadata": {},
   "outputs": [],
   "source": [
    "semantic_scores =[]\n",
    "for i in range(len(ref_embedding)):\n",
    "    semantic_scores.append(np.dot(ref_embedding[i],pred_embedding[i]) / (np.linalg.norm(ref_embedding[i])*(np.linalg.norm(pred_embedding[i]))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BLEU or ROUGE scores\n",
    "\n",
    "Use BLEU scores for machine translation evaluation and ROUGE for text summarization evaluation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for machine translation evaluation\n",
    "bleu_scores =[]\n",
    "for i in range(len(reference_en)):\n",
    "    bleu_scores.append(sentence_bleu(reference_en[i],prediction_en[i], smoothing_function=smoother.method4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for text summarization evaluation\n",
    "rouge_scores = []\n",
    "for i in range(len(reference_en)):\n",
    "    *pr, f = rouge_n_sentence_level(prediction_en[i], reference_en[i], 2) # 2 for ROUGE-2. ROUGE-N, ROUGE-L and ROUGE-W scores can also be obtained.\n",
    "    rouge_scores.append(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Human annotation scores\n",
    "\n",
    "Load the human annotation scores from the respective excel files as below,\n",
    "\n",
    "- For **DE-EN** translation, 'human annotated/DE-EN.xlsx'\n",
    "\n",
    "\n",
    "- For **RO-EN** translation, 'human annotated/RO-EN.xlsx'\n",
    "\n",
    "\n",
    "- For **giga word** summarization(titles),'human annotated/giga.xlsx'\n",
    "\n",
    "\n",
    "- For **CNN-DM** summariation, 'human annotated/CNN_900.xlsx'\n",
    "\n",
    "\n",
    "- For **Duc 2003** summarization,  'human annotated/duc2003.xlsx'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "metadata": {},
   "outputs": [],
   "source": [
    "human_annotation = pd.read_excel('human annotated/DE-EN.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "metadata": {},
   "outputs": [],
   "source": [
    "human_scores = human_annotation.iloc[:, 3].tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pearson correlation coefficient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.32502479700810627, 4.910746911787776e-26)"
      ]
     },
     "execution_count": 321,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# correlation between human annotated scores and Bleu or ROUGE scores\n",
    "\n",
    "#pearson correlation value, p-value\n",
    "pearsonr(human_scores, bleu_scores) #bleu_scores or rouge_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.6281325519832321, 7.251607375115274e-111)"
      ]
     },
     "execution_count": 319,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# correlation between human annotated scores and semantic similarity scores\n",
    "\n",
    "pearsonr(human_scores, semantic_scores) # expected to be higher(more correlated) than with Bleu or ROUGE scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
