{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Smooth Inverse Frequency (SIF)\n",
    "\n",
    "SIF shows a simple unsupervised method for sentence embedding can get results better than sophisticated supervised models like RNN's and LSTM's with a modification of weights for supervised models. This weighting improves performance by about 10% to 30% in textual similarity tasks.  SIF weighting scheme is shown below.\n",
    "\n",
    "It has new \"smoothing\" terms that allow for words occurring out of context, as well as high probabilities for words like and, not in all contexts. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!git clone https://github.com/PrincetonML/SIF.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[WinError 3] The system cannot find the path specified: '../SIF/src'\n",
      "C:\\Users\\d072726\\Documents\\Thesis\\SIF\\src\n"
     ]
    }
   ],
   "source": [
    "%cd ../SIF/src"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "import data_io, params, SIF_embedding\n",
    "import numpy as np\n",
    "from gensim.models import KeyedVectors\n",
    "import pandas as pd\n",
    "from nltk.translate.bleu_score import sentence_bleu\n",
    "from nltk.translate.bleu_score import SmoothingFunction\n",
    "smoother = SmoothingFunction()\n",
    "from rouge.rouge import rouge_n_sentence_level # pip install easy-rouge\n",
    "from scipy.stats import pearsonr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Error loading stopwords: <urlopen error [Errno 11001]\n",
      "[nltk_data]     getaddrinfo failed>\n",
      "[nltk_data] Error loading punkt: <urlopen error [Errno 11001]\n",
      "[nltk_data]     getaddrinfo failed>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# imports for preprocessing\n",
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize \n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pretrained word embeddings\n",
    "\n",
    "- Download fasttext pretrained word embeddings [here](https://dl.fbaipublicfiles.com/fasttext/vectors-wiki/wiki.en.vec)\n",
    "- Download glove pretrained word embeddings [here](http://nlp.stanford.edu/data/glove.840B.300d.zip)\n",
    "\n",
    "Unzip the glove embeddings and save the embeddings in a folder pretrained_embeddings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:gensim.models.utils_any2vec:loading projection weights from ../../pretrained_embeddings/wiki.en.vec\n",
      "INFO:gensim.models.utils_any2vec:loaded (2519370, 300) matrix from ../../pretrained_embeddings/wiki.en.vec\n"
     ]
    }
   ],
   "source": [
    "#For convience convert the fasttext and glove embeddings to word2vec format\n",
    "\n",
    "#for using fasttext embeddings\n",
    "fasttext_model = KeyedVectors.load_word2vec_format('../../pretrained_embeddings/wiki.en.vec')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:gensim.models.utils_any2vec:loading projection weights from ../../pretrained_embeddings/glove_word2vec.txt\n",
      "WARNING:gensim.models.utils_any2vec:duplicate word '����������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������' in ../../pretrained_embeddings/glove_word2vec.txt, ignoring all but first\n",
      "INFO:gensim.models.utils_any2vec:duplicate words detected, shrinking matrix size from 2196017 to 2196016\n",
      "INFO:gensim.models.utils_any2vec:loaded (2196016, 300) matrix from ../../pretrained_embeddings/glove_word2vec.txt\n"
     ]
    }
   ],
   "source": [
    "#for using glove embeddings\n",
    "\n",
    "glove_file = '../../pretrained_embeddings/glove.840B.300d.txt'\n",
    "tmp_file = '../../pretrained_embeddings/glove_word2vec.txt'\n",
    "#_ = glove2word2vec(glove_file, tmp_file)\n",
    "\n",
    "glove_model = KeyedVectors.load_word2vec_format(tmp_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "weightfile = '../auxiliary_data/enwiki_vocab_min200.txt' # each line is a word and its frequency\n",
    "weightpara = 1e-3 # the parameter in the SIF weighting scheme, usually in the range [3e-5, 3e-3]\n",
    "rmpc = 1 # number of principal components to remove in SIF weighting scheme"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_embedding_matrix(model):\n",
    "    Vocab = dict()\n",
    "    embedding = []\n",
    "    for i, word in enumerate(model.vocab):\n",
    "        embedding.append(model[word])       \n",
    "        Vocab[word] = i\n",
    "    embedding_matrix = np.array(embedding)\n",
    "    return embedding_matrix,Vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate the embeddings and words \n",
    "embedding_matrix, vocab = get_embedding_matrix(glove_model) #glove_model for using glove embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2196016, 300)"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding_matrix.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load testsets for evaluation\n",
    "\n",
    "The Automatically generated candidate texts (predictions) from machine translation or text summarization are evaluated against their reference texts. <br> Below are the testsets to be used for evaluation. \n",
    "\n",
    "- For **DE-EN** translation, <br> **Candidate-**   '../Testsets/DE-EN/multi30k.test.pred.en.atok'  **Reference-**      '../Testsets/DE-EN/test2016.en.atok'    <br>\n",
    "\n",
    "\n",
    "- For **RO-EN** translation, <br> **Candidate-**-   '../Testsets/RO-EN/newstest2016_output_1000.en'  **Reference-**    '../Testsets/RO-EN/newstest2016_ref_1000.en'  <br>\n",
    "\n",
    "\n",
    "- For **CNN-DM** summariation, <br> **Candidate-**   '../Testsets/CNN-DM/preprocessed_1000.pred'  **Reference-** '../Testsets/CNN-DM/preprocessed_1000.ref'  \n",
    "\n",
    "\n",
    "- For **DUC2003** summarization, <br> **Candidate-**  '../Testsets/DUC2003/duc2003.10_300000-500.txt'  **Reference-** '../Testsets/DUC2003/task1_ref0_duc2003-500.txt'  \n",
    "\n",
    "\n",
    "- For **Gigaword** summarization (titles), <br>  **Candidate-**  '../Testsets/Gigaword/giga.10_300000_500.txt'  **Reference-** '../Testsets/Gigaword/task1_ref0_giga_500.txt' "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "reference_doc = '../../testsets/duc/task1_ref0_duc2003-500.txt'\n",
    "prediction_doc = '../../testsets/duc/duc2003.10_300000-500.txt' \n",
    "\n",
    "with open( reference_doc ,'r') as ref, open( prediction_doc ,'r') as pred:\n",
    "    reference_en = ref.readlines()\n",
    "    prediction_en = pred.readlines()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Optional preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessing(doc, stop_words_remove=False):\n",
    "    remove_punctuation = []\n",
    "    preprocessed_doc = []\n",
    "    # keep only alphanumeric characters(remove punctuations)\n",
    "    remove_punctuation = [re.sub(r\"[^\\w]\", \" \", sent).lower().strip() for sent in doc] \n",
    "    \n",
    "    if stop_words_remove == True:\n",
    "        # remove stop words requires lower cased tokens\n",
    "        stop_words = set(stopwords.words(\"english\"))\n",
    "        for sent in doc:\n",
    "            filtered_sentence = [word for word in word_tokenize(sent.lower()) if not word in stop_words]\n",
    "            preprocessed_doc.append(' '.join(filtered_sentence))\n",
    "        return preprocessed_doc\n",
    "    else:\n",
    "        return remove_punctuation  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use only if you want to preprocess the sentences\n",
    "\n",
    "reference_en = preprocessing(reference_en, True) # True to remove stopwords, default only removes punctuation\n",
    "prediction_en = preprocessing(prediction_en, True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Semantic similarity scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# load word weights\n",
    "word2weight = data_io.getWordWeight(weightfile, weightpara) # word2weight['str'] is the weight for the word 'str'\n",
    "weight4ind = data_io.getWeight(vocab, word2weight) # weight4ind[i] is the weight for the i-th word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "def seq2weight(seq, mask, weight4ind):\n",
    "    weight = np.zeros(seq.shape).astype('float32')\n",
    "    for i in range(seq.shape[0]):\n",
    "        for j in range(seq.shape[1]):\n",
    "            if mask[i,j] > 0 and seq[i,j] >= 0:\n",
    "                weight[i,j] = weight4ind[seq[i,j]]\n",
    "    weight = np.asarray(weight, dtype='float32')\n",
    "    return weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set parameters\n",
    "params = params.params()\n",
    "params.rmpc = rmpc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load reference sentences\n",
    "x, m = data_io.sentences2idx(reference_en, vocab) # x is the array of word indices, m is the binary mask indicating whether there is a word in that location\n",
    "w = seq2weight(x, m, weight4ind) # get word weights\n",
    "\n",
    "# get SIF embedding\n",
    "embedding_ref = SIF_embedding.SIF_embedding(embedding_matrix, x, w, params) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load prediction sentences\n",
    "x, m = data_io.sentences2idx(prediction_en, vocab) # x is the array of word indices, m is the binary mask indicating whether there is a word in that location\n",
    "w = seq2weight(x, m, weight4ind) # get word weights\n",
    "\n",
    "# get SIF embedding\n",
    "embedding_pred = SIF_embedding.SIF_embedding(embedding_matrix, x, w, params) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "semantic_scores =[]\n",
    "for i in range(len(embedding_ref)):\n",
    "    semantic_scores.append(np.dot(embedding_ref[i],embedding_pred[i]) / (np.linalg.norm(embedding_ref[i])*(np.linalg.norm(embedding_pred[i]))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BLEU or ROUGE scores\n",
    "\n",
    "Use BLEU scores for machine translation evaluation and ROUGE for text summarization evaluation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for machine translation evaluation\n",
    "bleu_scores =[]\n",
    "for i in range(len(reference_en)):\n",
    "    bleu_scores.append(sentence_bleu(reference_en[i],prediction_en[i], smoothing_function=smoother.method4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for text summarization evaluation\n",
    "rouge_scores = []\n",
    "for i in range(len(reference_en)):\n",
    "    *pr, f = rouge_n_sentence_level(prediction_en[i], reference_en[i], 2) # 2 for ROUGE-2. ROUGE-N, ROUGE-L and ROUGE-W scores can also be obtained.\n",
    "    rouge_scores.append(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Human annotation scores\n",
    "\n",
    "Load the human annotation scores from the respective excel files as below,\n",
    "\n",
    "- For **DE-EN** translation, '../Human annotations/DE-EN.xlsx'\n",
    "\n",
    "\n",
    "- For **RO-EN** translation, '../Human annotations/RO-EN.xlsx'\n",
    "\n",
    "\n",
    "- For **CNN-DM** summariation, '../Human annotations/CNN_1000.xlsx'\n",
    "\n",
    "\n",
    "- For **DUC2003** summarization,  '../Human annotations/DUC2003.xlsx'\n",
    "\n",
    "\n",
    "- For **Gigaword** summarization (titles),  '../Human annotations/Gigaword.xlsx'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "human_annotation = pd.read_excel('../../human annotated/duc2003.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "human_scores = human_annotation.iloc[:, 2].tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pearson correlation coefficient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.2618920908180919, 2.7559701344461234e-09)"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# correlation between human annotated scores and Bleu or ROUGE scores\n",
    "\n",
    "#pearson correlation value, p-value\n",
    "pearsonr(human_scores, rouge_scores) #bleu_scores or rouge_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.14251804601732798, 0.0013668344947902107)"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# correlation between human annotated scores and semantic similarity scores\n",
    "\n",
    "pearsonr(human_scores, semantic_scores) # expected to be higher(more correlated) than with Bleu or ROUGE scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
