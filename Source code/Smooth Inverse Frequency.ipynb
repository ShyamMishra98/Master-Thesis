{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Smooth Inverse Frequency (SIF)\n",
    "\n",
    "SIF shows a simple unsupervised method for sentence embedding can get results better than sophisticated supervised models like RNN's and LSTM's with a modification of weights for supervised models. This weighting improves performance by about 10% to 30% in textual similarity tasks.  SIF weighting scheme is shown below.\n",
    "\n",
    "It has new \"smoothing\" terms that allow for words occurring out of context, as well as high probabilities for words like and, not in all contexts. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cloning into 'SIF'...\n"
     ]
    }
   ],
   "source": [
    "!git clone https://github.com/PrincetonML/SIF.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\d072726\\Downloads\\Master-Thesis\\Source code\\SIF\\src\n"
     ]
    }
   ],
   "source": [
    "%cd SIF/src"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "\n",
    "import data_io, params, SIF_embedding\n",
    "from gensim.models import KeyedVectors\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from nltk.translate.bleu_score import sentence_bleu\n",
    "from nltk.translate.bleu_score import SmoothingFunction\n",
    "smoother = SmoothingFunction()\n",
    "from rouge.rouge import rouge_n_sentence_level # pip install easy-rouge\n",
    "from scipy.stats import pearsonr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\d072726\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\d072726\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# imports for preprocessing\n",
    "\n",
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize \n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pretrained word embeddings\n",
    "\n",
    "- Download fasttext pretrained word embeddings [here](https://dl.fbaipublicfiles.com/fasttext/vectors-wiki/wiki.en.vec)\n",
    "- Download glove pretrained word embeddings [here](http://nlp.stanford.edu/data/glove.840B.300d.zip)\n",
    "\n",
    "Unzip the glove embeddings and save the embeddings in a folder Pretrained_embeddings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:gensim.models.utils_any2vec:loading projection weights from ../../../Pretrained_embeddings/wiki.en.vec\n",
      "INFO:gensim.models.utils_any2vec:loaded (2519370, 300) matrix from ../../../Pretrained_embeddings/wiki.en.vec\n"
     ]
    }
   ],
   "source": [
    "#For convience convert the fasttext and glove embeddings to word2vec format\n",
    "\n",
    "#for using fasttext embeddings\n",
    "\n",
    "fasttext_model = KeyedVectors.load_word2vec_format('../../../Pretrained_embeddings/wiki.en.vec')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:gensim.models.utils_any2vec:loading projection weights from ../../pretrained_embeddings/glove_word2vec.txt\n",
      "WARNING:gensim.models.utils_any2vec:duplicate word '����������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������' in ../../pretrained_embeddings/glove_word2vec.txt, ignoring all but first\n",
      "INFO:gensim.models.utils_any2vec:duplicate words detected, shrinking matrix size from 2196017 to 2196016\n",
      "INFO:gensim.models.utils_any2vec:loaded (2196016, 300) matrix from ../../pretrained_embeddings/glove_word2vec.txt\n"
     ]
    }
   ],
   "source": [
    "#for using glove embeddings\n",
    "\n",
    "glove_file = '../../../Pretrained_embeddings/glove.840B.300d.txt'\n",
    "tmp_file = '../../../Pretrained_embeddings/glove_word2vec.txt'\n",
    "#_ = glove2word2vec(glove_file, tmp_file)\n",
    "\n",
    "glove_model = KeyedVectors.load_word2vec_format(tmp_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "weightfile = '../auxiliary_data/enwiki_vocab_min200.txt' # each line is a word and its frequency\n",
    "weightpara = 1e-3 # the parameter in the SIF weighting scheme, usually in the range [3e-5, 3e-3]\n",
    "rmpc = 1 # number of principal components to remove in SIF weighting scheme"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_embedding_matrix(model):\n",
    "    Vocab = dict()\n",
    "    embedding = []\n",
    "    for i, word in enumerate(model.vocab):\n",
    "        embedding.append(model[word])       \n",
    "        Vocab[word] = i\n",
    "    embedding_matrix = np.array(embedding)\n",
    "    return embedding_matrix,Vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate the embeddings and words \n",
    "embedding_matrix, vocab = get_embedding_matrix(fasttext_model) #glove_model for using glove embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2519370, 300)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding_matrix.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load testsets for evaluation\n",
    "\n",
    "The Automatically generated candidate texts (predictions) from machine translation or text summarization are evaluated against their reference texts. <br> Below are the testsets to be used for evaluation. \n",
    "\n",
    "- For **DE-EN** translation, <br> **Candidate-**   '../Testsets/DE-EN/multi30k.test.pred.en.atok'  **Reference-**      '../Testsets/DE-EN/test2016.en.atok'    <br>\n",
    "\n",
    "\n",
    "- For **RO-EN** translation, <br> **Candidate-**-   '../Testsets/RO-EN/newstest2016_output_1000.en'  **Reference-**    '../Testsets/RO-EN/newstest2016_ref_1000.en'  <br>\n",
    "\n",
    "\n",
    "- For **CNN-DM** summariation, <br> **Candidate-**   '../Testsets/CNN-DM/preprocessed_1000.pred'  **Reference-** '../Testsets/CNN-DM/preprocessed_1000.ref'  \n",
    "\n",
    "\n",
    "- For **DUC2003** summarization, <br> **Candidate-**  '../Testsets/DUC2003/duc2003.10_300000-500.txt'  **Reference-** '../Testsets/DUC2003/task1_ref0_duc2003-500.txt'  \n",
    "\n",
    "\n",
    "- For **Gigaword** summarization (titles), <br>  **Candidate-**  '../Testsets/Gigaword/giga.10_300000_500.txt'  **Reference-** '../Testsets/Gigaword/task1_ref0_giga_500.txt' "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "candidate_doc =  '../../../Testsets/DE-EN/multi30k.test.pred.en.atok'  \n",
    "reference_doc = '../../../Testsets/DE-EN/test2016.en.atok' \n",
    "\n",
    "with  open( candidate_doc ,'r') as cand, open( reference_doc ,'r') as ref:\n",
    "    candidate_en = cand.readlines()\n",
    "    reference_en = ref.readlines()   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['A man in an orange hat presenting something .\\n',\n",
       " 'A Boston traveler runs across lush , green fence in front of a white fence .\\n',\n",
       " 'A girl in a karate uniform is blocking a board with a kick .\\n',\n",
       " 'Five people in winter jackets and helmets are standing in the snow with vials in the background .\\n',\n",
       " 'People moving off the roof of a house .\\n']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "candidate_en[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['A man in an orange hat starring at something .\\n',\n",
       " 'A Boston Terrier is running on lush green grass in front of a white fence .\\n',\n",
       " 'A girl in karate uniform breaking a stick with a front kick .\\n',\n",
       " 'Five people wearing winter jackets and helmets stand in the snow , with snowmobiles in the background .\\n',\n",
       " 'People are fixing the roof of a house .\\n']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reference_en[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Optional preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessing(doc, stop_words_remove=False):\n",
    "    remove_punctuation = []\n",
    "    preprocessed_doc = []\n",
    "    # keep only alphanumeric characters(remove punctuations)\n",
    "    remove_punctuation = [re.sub(r\"[^\\w]\", \" \", sent).lower().strip() for sent in doc] \n",
    "    \n",
    "    if stop_words_remove == True:\n",
    "        # remove stop words requires lower cased tokens\n",
    "        stop_words = set(stopwords.words(\"english\"))\n",
    "        for sent in doc:\n",
    "            filtered_sentence = [word for word in word_tokenize(sent.lower()) if not word in stop_words]\n",
    "            preprocessed_doc.append(' '.join(filtered_sentence))\n",
    "        return preprocessed_doc\n",
    "    else:\n",
    "        return remove_punctuation  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use only if you want to preprocess the sentences\n",
    "\n",
    "candidate_en = preprocessing(candidate_en, False) # True to remove stopwords, default only removes punctuation\n",
    "reference_en = preprocessing(reference_en, False) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Semantic similarity scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# load word weights\n",
    "\n",
    "word2weight = data_io.getWordWeight(weightfile, weightpara) # word2weight['str'] is the weight for the word 'str'\n",
    "weight4ind = data_io.getWeight(vocab, word2weight) # weight4ind[i] is the weight for the i-th word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def seq2weight(seq, mask, weight4ind):\n",
    "    weight = np.zeros(seq.shape).astype('float32')\n",
    "    for i in range(seq.shape[0]):\n",
    "        for j in range(seq.shape[1]):\n",
    "            if mask[i,j] > 0 and seq[i,j] >= 0:\n",
    "                weight[i,j] = weight4ind[seq[i,j]]\n",
    "    weight = np.asarray(weight, dtype='float32')\n",
    "    return weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set parameters\n",
    "params = params.params()\n",
    "params.rmpc = rmpc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load candidate sentences\n",
    "# change iteritems to items and xrange to range in the source code of SIF for python3\n",
    "\n",
    "x, m = data_io.sentences2idx(candidate_en, vocab) # x is the array of word indices, m is the binary mask indicating whether there is a word in that location\n",
    "w = seq2weight(x, m, weight4ind) # get word weights\n",
    "\n",
    "# get SIF embedding\n",
    "\n",
    "cand_embedding = SIF_embedding.SIF_embedding(embedding_matrix, x, w, params) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load reference sentences\n",
    "\n",
    "x, m = data_io.sentences2idx(reference_en, vocab) # x is the array of word indices, m is the binary mask indicating whether there is a word in that location\n",
    "w = seq2weight(x, m, weight4ind) # get word weights\n",
    "\n",
    "# get SIF embedding\n",
    "\n",
    "ref_embedding = SIF_embedding.SIF_embedding(embedding_matrix, x, w, params) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cosine similarity function\n",
    "\n",
    "semantic_scores =[]\n",
    "for i in range(len(cand_embedding)):\n",
    "    semantic_scores.append(np.dot(cand_embedding[i],ref_embedding[i]) / (np.linalg.norm(cand_embedding[i])*(np.linalg.norm(ref_embedding[i]))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BLEU or ROUGE scores\n",
    "\n",
    "Use BLEU scores for machine translation evaluation and ROUGE for text summarization evaluation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for machine translation evaluation\n",
    "\n",
    "bleu_scores =[]\n",
    "for i in range(len(reference_en)):\n",
    "    bleu_scores.append(sentence_bleu(candidate_en[i],reference_en[i], smoothing_function=smoother.method4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for text summarization evaluation\n",
    "\n",
    "rouge_scores = []\n",
    "for i in range(len(reference_en)):\n",
    "    *pr, f = rouge_n_sentence_level(candidate_en[i], reference_en[i], 1) # 2 for ROUGE-2. ROUGE-N, ROUGE-L and ROUGE-W scores can also be obtained.\n",
    "    rouge_scores.append(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Human annotation scores\n",
    "\n",
    "Load the human annotation scores from the respective excel files as below,\n",
    "\n",
    "- For **DE-EN** translation, '../Human annotations/DE-EN.xlsx'\n",
    "\n",
    "\n",
    "- For **RO-EN** translation, '../Human annotations/RO-EN.xlsx'\n",
    "\n",
    "\n",
    "- For **CNN-DM** summariation, '../Human annotations/CNN_1000.xlsx'\n",
    "\n",
    "\n",
    "- For **DUC2003** summarization,  '../Human annotations/DUC2003.xlsx'\n",
    "\n",
    "\n",
    "- For **Gigaword** summarization (titles),  '../Human annotations/Gigaword.xlsx'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "human_annotation = pd.read_excel('../../../Human annotations/DE-EN.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "human_scores = human_annotation.iloc[:, 2].tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pearson correlation coefficient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.3901802069640419, 1.0390848166845472e-37)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# correlation between human annotated scores and Bleu or ROUGE scores\n",
    "\n",
    "#pearson correlation value, p-value\n",
    "\n",
    "pearsonr(human_scores, bleu_scores) # bleu_scores or rouge_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.6511392184339738, 1.110425667360541e-121)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# correlation between human annotated scores and semantic similarity scores\n",
    "\n",
    "pearsonr(human_scores, semantic_scores) # expected to be higher(more correlated) than with Bleu or ROUGE scores"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
